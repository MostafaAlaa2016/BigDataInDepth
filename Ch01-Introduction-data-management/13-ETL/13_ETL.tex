%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Data Integration and ETL Layer}

\begin{frame}
	\frametitle{Data Integration}

	\includegraphics[width=\textheight]{./Figures/chapter-01/WWH-Thumb.png}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
	\frametitle{Data Integration: The Big Picture}

	\input{Ch01-Introduction-data-management/13-ETL/Figures/fig_tikz_etl_overview.tex}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
	\frametitle{Data Integration: The Big Picture}

	\input{Ch01-Introduction-data-management/13-ETL/Figures/fig_tikz_etl_overview_simplified.tex}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
	\frametitle{What is ETL?}

	\begin{itemize}
		\item The ETL is the process of
		\begin{itemize}
			\item  \textbf{Extracting}: the data from one or more source system
			\item  \textbf{Transformation}: apply some rules over the extracted data including
			\begin{itemize}
				\item Cleansing ex: remove null, or trim spaces.
				\item Drop duplicates.
				\item joining with lookups to validate values or enrich the data.
				\item Reshaping or changing the data structure.
				\item Adding new columns or removing columns from these data.
				\item Change of data granularity.
				\item Convert data types.
			\end{itemize}
			\item \textbf{Loading}: loading the transformed data into the target table based on the required format.
		\end{itemize}
	\end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
	\frametitle{What is ETL?}

	\begin{itemize}
		\item The ETL (Extraction, Transformation, Loading) is the primary core function for any data engineering (DWH) team.

		\item This team takes the delivered output from the previous stage (data modeling) and start to implement the mapping.

		\item The implementation of the ETL preferred to be unified across the team members and the organization.

	\end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
	\frametitle{Why?}
	\centering
	\begin{block}{Why ETL become mandatory in any DWH system? }
		Because of the rapidly increase in the data volumes,
		and the variety of the data types structure, semi-structure, and non-structure data.
	\end{block}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
	\frametitle{ETL Characteristics}
	%%
	\begin{itemize}
		\item Successful ETL design have the following characteristics:
		\begin{itemize}
			\item [\faCheckSquareO] Maintainable.
			\item [\faCheckSquareO] Reusable.
			\item [\faCheckSquareO] Well-Performed.
			\item [\faCheckSquareO] Reliable.
			\item [\faCheckSquareO] Resilient.
			\item [\faCheckSquareO] Secure.
		\end{itemize}
	\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
	\frametitle{ETL Best Practice}
	\begin{itemize}
		\item The keys to  most of ETL implementation as following:
		\begin{itemize}

			\item [\faCheckSquareO] \blue{ \textbf{Auditing}}

			\item [\faCheckSquareO] \textbf{Managing Bad Data (Rejection Handling)}

			\item [\faCheckSquareO] \textbf{Data Lineage}

			\item [\faCheckSquareO] \textbf{Modularity}

			\item [\faCheckSquareO] \textbf{Logging}

			\item [\faCheckSquareO] \textbf{Error Handling}

			\item [\faCheckSquareO] \textbf{Atomicity}

		\end{itemize}
	\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\midTitle{ETL: Auditing}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
	\frametitle{ETL Auditing}
	\begin{itemize}
		\item Example
		\begin{itemize}
			\item We have a billing source system and we need to integrate this source system in our DWH.
			\item Assume you get every day around 3M rows of data with total amount around 1M\$.
			\item Auditing helps us into three parts:
			\begin{itemize}
				\item Confirm the received rows are inserted into the target or (target + malformed = source).
				\item Identify the abnormal behavior if the source row changed maybe 3M (+/- 1\%). The same metrics for the target and malformed records to be analyzed.
				\item Identify the abnormal behavior in the total aggregations, for example if we have a peak up to the total amount more than the normal (+/- 5\%).
			\end{itemize}
		\end{itemize}
	\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
	\frametitle{ETL Auditing}
	%%
	\begin{itemize}
		\item Auditing: The most important key to have a well-designed ETL architecture is to support the auditing row counts, aggregation, and other metrics based on the business and the use case. The first and most important quality gate is based on the auditing.

		\begin{itemize}
			\item Auditing help identifying the data abnormalities even if the ETL job doesn't have any errors.
			\item Auditing implementation differs between systems based on the use case.
			\item It is Customized based on the source system's criticality that could add more auditing metrics.
			\item We could extend auditing functions to be queryable on database monitoring or dashboards.


		\end{itemize}
	\end{itemize}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\midTitle{ETL: Logging}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
	\frametitle{ETL Logging}
	%%
	\begin{itemize}
		\item Logging: is key to any successful ETL architecture, and it requires implementing a general strategy for all projects.

		\begin{itemize}
			\item ETL logging includes logs of any activtities or events that occur in the ETL job before, during, and after every stage.
			\item Some of the ETL software tools have their logs for the ETL; however, it could extend to other logs added to enhanced the ETL logging.
		\end{itemize}
	\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
	\frametitle{ETL Logging}
	%%
	\begin{itemize}

		\item What types of events or metrics do we need to capture during ETL logging?
		\begin{itemize}

			\item \textit{Start and stop events}.
			\item \textit{Status}
			\item \textit{Errors and other exceptions}
			\item \textit{Audit information}
			\item \textit{Testing and debugging information}
		\end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}
	\frametitle{ETL Logging}
	%%
	\begin{itemize}

		\item Some consideration during the building of the logging strategy:
		\begin{itemize}
			\item How to make your logs \textbf{format} easy for analysis?
			\item Do you have a dashboard or tools for logs visualization, or will it be an ad-hoc fashion?
			\item Who is the audience for these logs, and what are their needs?
			\item Are there any security requirements or restrictions for data logging?
			\item What is the retention policy?
		\end{itemize}
	\end{itemize}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\midTitle{ETL: Managing Bad Data (Rejection Handling)}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
	\frametitle{ETL: Managing Bad Data (Rejection Handling)}
	%%
	\begin{itemize}
		\item In some systems, you get a malformed data, and it needs special handling (not removing).
		\item It means the data is not accurate or as expected when compared to the same source system.
		\item If we use this data as-is, we are risk affecting the quality of the business reports.
		\item To manage the malformed records, we need to apply the following steps
		\begin{itemize}
			\item  Define what is the meaning by well-formed records or accurate record.
			\item  Configure handling actions for the malformed records.
			\item  \red{Configure handling actions for the malformed records.}.

		\end{itemize}
	\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
	\frametitle{ETL: Managing Bad Data (Rejection Handling)}

	\begin{itemize}
		\item Example
		\begin{itemize}
			\item  We have a CSV file that contains 5 columns, and we need to apply the ETL on this file.
		\end{itemize}
	\end{itemize}



\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
	\frametitle{ETL: Managing Bad Data Part 1}

\begin{lstlisting}[style=json]
{
"sourceName": "3G_ERCSN",
"dataFileDelimiter": "|",
"totalInputFileColumns": "5",
"rejectedRecordsPath": "/RAW_ZONE/REJECTION/3G_ERCSN/",
"schemaName": "MOD",
"targetTable": "Singl_KPI",
"saveMode": "Append",
"inputFileFormat": "processing",
"outputFormat": "orc",
"header": "false",
"partitionColumns_3G_ERCSN": "event_date,batch_id",
"getDetailedAuditStats": "false",
"inputSchema": [
{
]
}
\end{lstlisting}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
	\frametitle{ETL: Managing Bad Data Part 2}

\begin{lstlisting}[style=json,basicstyle=\scriptsize ]
{
"columnName": "C0",
"columnType": "IntegerType",
"isNullable": "true"
},
{
"columnName": "C1",
"columnType": "StringType",
"isNullable": "true"
},
.
.
.
{
"columnName": "C4",
"columnType": "TimestampType",
"isNullable": "true"
}
\end{lstlisting}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\midTitle{ETL: Modularity}
\begin{frame}
	\frametitle{ETL Modularity}
	%%
	\begin{itemize}
		\item ETL architecture is not only the quality of data but also how the code is reusable and modularized. 
		\item ETL architecture is not only the quality of data but also how the code is reusable and modularized. 		
		\item How to achieve this modularity?
		\begin{itemize}
			\item Design template jobs for each part of the system.
			\item Standard methods and strategy for common tasks such as logging, error handling, and rejecting handling.
			\item  Reduce the duplicate code by creating  common libraries for the ETL.
			\item  Create common functionality for unit testing.

		\end{itemize}
	\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
	\frametitle{ETL Modularity}
	%%
	\begin{itemize}
		\item How does this affect the team?
		\begin{itemize}
			\item Maintainability.
			\item Debugging.
			\item Investigation.
			\item Testing.
			\item Sharing the tasks between the team.

		\end{itemize}
		\item This part is a continuous enhancement part.
	\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\midTitle{ETL: Data Lineage}
\begin{frame}
	\frametitle{ETL: Data Lineage}
	%%
	\begin{itemize}
		\item Data Lineage is an essential part of our process to understand how this data transformed and where this data originated.
		\item It helps to make the trust in the data by connecting the target into the source.
		\item It helps with data tracing at the row level.
	\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
	\frametitle{ETL: Data Lineage Example}
	%%
	\begin{itemize}
		\item  We have a CSV file that contains 5 columns and we need to apply ETL process for this file assume the name is 3g\_ercsn.csv it could be any name.
		\item After process this file, we rename this file to be filename\_batch\_id.
	\end{itemize}

	\begin{adjustbox}{max width=.99\textwidth}
		\begin{tabular}{| l | l | l | l | l| a|}
			\hline
			trns\_id & cell\_id & cust\_number & app & trns\_ts & batch\_id \\
			\hline
			\hline
			123 & C15343   & 503987123 & fb & 2020-04-25 12:12:33.4 &20200426020202\\
			3436 & C15341 & 503987123 & fb & 2020-04-25 15:12:33.4&20200426020202\\
			43634 & C15353   & 503987135 & twitter & 2020-04-25 18:12:33.4&20200426020202\\
			32632 & C15123   & 503987151 & youtube & 2020-04-25 22:12:33.4&20200426020202\\
			\hline
		\end{tabular}
	\end{adjustbox}



\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\midTitle{ETL: Error Handling}

\begin{frame}
	\frametitle{ETL Error Handling}
	%%
	\begin{itemize}
		\item Error handling answers a question, What should we do if the process failed?
		\item It also shows can prevent failure and handle these errors.
		\item We deal with errors using different strategies:
		\begin{itemize}
			\item Fail safe (a.k.a. graceful shutdown/stop).
			\item Fail fast.
			\item Design error handling framework it includes: prevention and response.
			\item Design framework dealing with error responses.

		\end{itemize}
	\end{itemize}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\midTitle{ETL: Atomicity}
\begin{frame}
	\frametitle{ETL Atomicity}
	%%
	\begin{itemize}
		\item Atomicity refers to breaking more significant parts into smaller individual parts.
		\item It also refers to how to split bigger ETL process or job into smaller parts.
		\item Implementation of the atomicity pattern involves the identification of business parts and how to split it into smaller units for proper execution.
		\item We refer to the anti-pattern for atomicity by monolithic.
		\item Atomicity requires the ETL engineer to have some overview of the whole project cycle and how we can split it without affecting the business.
	\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
	\frametitle{ETL Atomicity}
	Why do we need Atomicity?
	\begin{itemize}
		\item Maintainability and readability of the code.
		\item It helps in code tracing, testing, and enhancing.
		\item Agile development and parallel work.
		\item Avoid a single failure job, which enhances performance and resource optimization.
	\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\midTitle{ETL: Paper and Pen Design}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
	\frametitle{References}
	\begin{itemize}
		\item \href{https://www.timmitchell.net/etl-best-practices/}{ETL Best Practices By Tim Mitchell}
	\end{itemize}

\end{frame}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../main"
% !TeX root = ../../main.tex
%%% TeX-engine: xetex
%%% End: