\section{Introduction To Distributed Systems}
%\input{Ch02-Introduction-To-Distributed-Systems/Ch01-01-sub-intro}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\\
%\input{Ch02-Introduction-To-Distributed-Systems/Ch01-02-sub-intro}

\subsection{Introduction To Hadoop}

\begin{frame}[c]{ }
	\centering     
	
	\textcolor{offgreen}{ \large Previous video recap!}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
	\frametitle{Lecture Objectives }
	\begin{itemize}  [<+->]
		\item Why do we need Hadoop?
		\item Hadoop Distributed File System (HDFS) concepts.
		\item Go dive into MapReduce.
		\item Hadoop architecture and its echosystems.
		\item How does Hadoop store, distribute, and process the data?

		
	\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]{ }
	\frametitle{Introduction to Hadoop }
	\begin{itemize}  [<+->]
	\item Apache Hadoop's MapReduce and HDFS components were inspired by Google papers on MapReduce and Google File System
	
\end{itemize}
	\footnotetext[1]{From Wikipedia  \href{https://en.wikipedia.org/wiki/Apache_Hadoop}{https://en.wikipedia.org/wiki/Apache_Hadoop}	} 
	\footnotetext[2]{Google File System  \href{http://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf}{http://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf}	} 
	
	\footnotetext[3]{MapReduce: Simplifed Data Processing on Large Clusters \href{https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf}{https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf}	} 
	
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]{ }
		\frametitle{Introduction to Hadoop }
	\centering     
	
	\textcolor{offgreen}{ \large Is it already dead?}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
	\frametitle{What is Hadoop? }
	\begin{itemize}  [<+->]
		\item A distributed software framework to store, process, and analzing "Large Scale of Data AKA. Big Data"
		\item It is open source!
		\item It runs on commodity (standard) hardware.
		\item Hadoop architecture and its echosystems.		
	\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
	\frametitle{Hadoop Core Components }
	\begin{itemize}  [<+->]
		
		\item Hadoop HDFS: Data Storage Layer (File System).
		\item Hadoop MapReduce: The processing engine (compute paradigm) in Hadoop.
		\item Hadoop YARN: The resource manager in Hadoop.
		
	\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]{ }
	\frametitle{Introduction to Hadoop }
	\centering     
	
	\textcolor{offgreen}{ \large What are the alternatives?}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
	\frametitle{Hadoop Core Components }
	\begin{itemize}  
		
		\item \sout{Hadoop HDFS} \textcolor{offyellow}{S3/GFS}:  Data Storage Layer (File System).
		\item \sout{Hadoop MapReduce} \textcolor{offyellow}{Spark/Flink}: The processing engine (compute paradigm) in Hadoop.
		\item \sout{Hadoop YARN} \textcolor{offyellow}{Kubernetes}: The resource manager in Hadoop.
		% \textcolor{brown}{
	\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]{ }
	\frametitle{Introduction to Hadoop }
	\centering     
	
	\textcolor{offgreen}{ \large Can we use these alternatives on prem?}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
	\frametitle{Hadoop Echosystem }
	\begin{figure}
	\centering
	\input{./Figures/chapter-02/hadoop_echo.tex}
	\caption{Hadoop Architecture } \label{fig:DS3}
\end{figure}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]{ }
	\frametitle{Hadoop Motivation }
	\centering     
	
	\textcolor{offgreen}{ \large Hadoop Motivation}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]{ }
	\frametitle{Hadoop Motivation }
	Processing:
	\begin{itemize}  [<+->]
	
	\item Traditional Computation was depending on bigger computers to deal with bigger data.
	\item This method has a bottleneck in the computation (Moore's Law), but this couldn't keep up.
	\item The better solution requires more computers (distributed computing framework).
	
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]{ }
	\frametitle{Hadoop Motivation }
	Storage:
	\begin{itemize}  [<+->]
		
		\item Traditional Computation store the data in a central unit.
		\item Data was copied (moved) to the computation nodes, for example, IBM Data stage or Talend.
		\item The process of copying or moving the data was fine when we move a small amount of data, but the big data will cause lots of problems, especially in the network bandwidth, and data moving will be costly.
		
	\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]{ }
	\frametitle{Requirements for The New Approach }
	
	
	\begin{itemize}  [<+->]
		\item [--] Fault Tolerance.
		\item [--] High Availability.
		\item [--] Reliability.
		\item [--] Scalability.
		\item [--] Consistency.
		\item [--] Data Locality.
		\item [--] Economic.
		
	\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]{ }
	\frametitle{Requirements for The New Approach }
	Economic
	\begin{itemize}  [<+->]
		\item [--] {\footnotesize It uses commodity (Standard/Economic) hardware}.

	\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]{ }
	\frametitle{Requirements for The New Approach }
	Data Locality
	\begin{itemize}  [<+->]
		\item [--] {\footnotesize It brings the program to the data rather than the data to the program. It runs the computation where the data reside.}		
		\item [--] {\footnotesize HDFS is strongly consistent.}		
	\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]{ }
	\frametitle{Requirements for The New Approach }
	Fault Tolerance
	\begin{itemize}  [<+->]
		\item [--] {\footnotesize It is the property that enables a system to continue operating properly in the event of the failure of (or one or more faults within) some of its components}.
		\item [--] {\footnotesize The ability of maintaining functionality when portions of a system break down is referred to as graceful degradation}.
		\item [--] {\footnotesize A fault-tolerant design enables a system to continue its intended operation, possibly at a reduced level, rather than failing completely, when some part of the system fails.}
		
	\end{itemize}
	\footnotetext[1]{From Wikipedia  \href{https://en.wikipedia.org/wiki/Fault_tolerance}{https://en.wikipedia.org/wiki/Fault_tolerance}	} 
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]{ }
	\frametitle{Requirements for The New Approach }
	High Availability
	\begin{itemize}  [<+->]
		\item [--] {\footnotesize High availability (HA) is a characteristic of a system which aims to ensure an agreed level of operational performance, usually uptime, for a higher than normal period}.
		\item [--] {\footnotesize The availability of the cluster (system) to operate without any downtime despite any hardware failure. The data or the system should be available and accessed from any alternative way}.
		
	\end{itemize}
	\footnotetext[1]{From Wikipedia  \href{https://en.wikipedia.org/wiki/High_availability}{https://en.wikipedia.org/wiki/High_availability}	} 
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]{ }
	\frametitle{Requirements for The New Approach }
	Reliability
	\begin{itemize}  [<+->]
		\item [--] {\footnotesize The data reliably stored on the cluster of machine despite machine failures. }		
	\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]{ }
	\frametitle{Requirements for The New Approach }
	Scalability
	\begin{itemize}  [<+->]
		\item [--] {\footnotesize The system must be highly scalable in both vertical and horizontal. This means we can add a new node to an existing cluster easily or add new hardware to an existing node.}		
	\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]{ }
	\frametitle{Requirements for The New Approach }
	Consistency
	\begin{itemize}  [<+->]
		\item [--] {\footnotesize Any failure during the execution job shouldn't affect the outcome of the job.}		
		\item [--] {\footnotesize HDFS is strongly consistent.}		
	\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]{ }
	\frametitle{Core Hadoop Concepts }
	\centering     
	
	\textcolor{offgreen}{ \large Hadoop Core Concepts}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]{ }
	\frametitle{Hadoop Core Concepts }
	
	
	\begin{itemize}  [<+->]
		\item [--] Hadoop is scalable and fault-tolerant.
		\item [--] Hadoop replicates the data to increase the availability and reliability.
		\item [--] Hadoop brings the program to the data.
		\item [--] Applications are written in high-level code.
		\item [--] Hadoop reduces the data movement (shuffle) between the nodes.
		
	\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]{ }
	\frametitle{Core Hadoop Concepts }
	\centering     
	
	\textcolor{offgreen}{ \large Hadoop Core Components}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]{ }
	\frametitle{Hadoop Core Concepts }
	
	
	\begin{itemize}  [<+->]
		\item [--] HDFS.
		\item [--] Map-Reduce.
		\item [--] YARN.
		
	\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]{ }
	\frametitle{HDFS }
	
	
	\begin{itemize}  [<+->]
		\item [--] HDFS responsible for storing the data on the hadoop cluster.
		\item [--] Data is split into blocks with configurable block size, for example 64MB, 128MB, 512MB.
		\item [--] Each data block is replicated and distributed across the cluster data node. This replication is configrable and by default three replica.
		\item [--] Each block is stored in three different nodes. It is recommended to have two nodes in the same rack and the third one in a different rack.
		
	\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]{ }
	\frametitle{HDFS }
	
	
	\begin{itemize}  [<+->]
		\item [--] {\footnotesize HDFS is responsible for storing the data on the Hadoop cluster.}
		\item [--] {\footnotesize Data is split into blocks with configurable block size, for example, 64MB, 128MB, and 512MB.}
		\item [--] {\footnotesize Each data block is replicated and distributed across the cluster data node. This replication is configurable, and by default, three replica (folds).}
		\item [--] {\footnotesize Each block is stored in three different nodes. It is recommended to have two nodes in the same rack and the third one in a different rack.}
		\item [--] {\footnotesize A \textit{NameNode} keeps track of the location of the blocks and which blocks make up these files. These details known as \textit{metadata}.}
	\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]{ }
	\frametitle{HDFS }
		\begin{figure}
		\centering
		\input{./Figures/chapter-02/hdfs.tex}
		\caption{Hadoop Architecture } \label{fig:hdfs}
	\end{figure}
	

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{Further Readings and Assignment}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Local Variables:
%%%% mode: latex
%%%% TeX-master: "../main"
%% !TeX root = ../main.tex
%%%% TeX-engine: xetex
%%%% End: